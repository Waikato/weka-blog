<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>WEKA Blog (Posts about github)</title><link>https://waikato.github.io/weka-blog/</link><description></description><atom:link href="https://waikato.github.io/weka-blog/categories/github.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 04 Jul 2020 08:21:35 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>New WekaDeeplearning4j Release - Pretrained Models, Feature Extraction Update, and more</title><link>https://waikato.github.io/weka-blog/posts/2020-07-04-wekaDeeplearning4j-1.6.0/</link><dc:creator>Eibe Frank</dc:creator><description>&lt;div&gt;&lt;div class="section" id="pretrained-models"&gt;
&lt;h2&gt;Pretrained Models&lt;/h2&gt;
&lt;p&gt;The package previously already contained a model zoo—a set of model architectures designed by others (e.g., AlexNet, ResNet50)—but there was no easy way to use a pretrained checkpoint in Wdl4jMlpClassifier so training these models had to be done from scratch. The new release of WekaDeeplearning4j both expands the model zoo to contain over 30 models and provides an easy way to initialize them with pre-trained weights that have been made publicly available for these models. This makes it even easier to start playing with state-of-the-art neural networks (e.g., EfficientNet): not only do you not need programming experience—due to the WEKA GUI—but now you don't even need a beefy GPU to start getting useful results because these models can simply be used as feature extractors without any extra training, simply using the pre-trained weights.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="updated-dl4jmlpfilter"&gt;
&lt;h2&gt;Updated Dl4jMlpFilter&lt;/h2&gt;
&lt;p&gt;This filter allows you to use a model—which can now be a pretrained model from the Model Zoo—as a feature extractor, converting an image dataset into a numeric form that can be used with any off-the-shelf WEKA classifier. In the new version, the filter also supports multiple feature extraction layers: by default the last dense layer will be used, but you can alternatively choose any intermediary layer as well, concatenating the activations from the two layers. This opens up a huge new world of experimentation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="image-dataset-conversion-script"&gt;
&lt;h2&gt;Image Dataset Conversion Script&lt;/h2&gt;
&lt;p&gt;Some image classification datasets come in a simple 'folder-organised' fashion, where collections of images are split into subfolders, with the name of each subfolder providing the class of all images within it. To make it easier to work with these types of image datasets, the package now includes the &lt;cite&gt;ImageDirectoryLoader&lt;/cite&gt; which can load in datasets of this form.&lt;/p&gt;
&lt;p&gt;Check out the &lt;a class="reference external" href="https://deeplearning.cms.waikato.ac.nz"&gt;documentation&lt;/a&gt; for more info on these new features!&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>github</category><guid>https://waikato.github.io/weka-blog/posts/2020-07-04-wekaDeeplearning4j-1.6.0/</guid><pubDate>Sat, 04 Jul 2020 06:06:00 GMT</pubDate></item><item><title>Weka Debian packages</title><link>https://waikato.github.io/weka-blog/posts/2019-09-23-weka-debian-packages/</link><dc:creator>FracPete</dc:creator><description>&lt;div&gt;&lt;p&gt;Users installing Weka on Linux must have always felt left out
a bit, with no installer available, instead having to deal with
just a ZIP file. For power users, that would not have mattered,
but users new to Linux may have found that a bit more challenging.&lt;/p&gt;
&lt;p&gt;Well, things have changed - at least for users of Debian or
one of its many derivatives like Ubuntu - with the advent
of &lt;a class="reference external" href="https://www.cs.waikato.ac.nz/~ml/weka/snapshots/weka_snapshots.html"&gt;snapshots&lt;/a&gt;
being available for download as &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Deb_%28file_format%29"&gt;Debian packages&lt;/a&gt; (stable 3.8 and developer version).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://waikato.github.io/weka-blog/posts/2019-09-23-weka-debian-packages/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>github</category><guid>https://waikato.github.io/weka-blog/posts/2019-09-23-weka-debian-packages/</guid><pubDate>Mon, 23 Sep 2019 01:21:00 GMT</pubDate></item><item><title>Micro averages in multi-class classification</title><link>https://waikato.github.io/weka-blog/posts/2019-02-16-micro_average/</link><dc:creator>Eibe Frank</dc:creator><description>&lt;div&gt;&lt;p&gt;When evaluating multi-class classification models, Weka outputs a weighted average of the per-class precision, recall, and F-measure: it computes these statistics for each class individually, treating the corresponding class as the "positive" class and the union of the other classes as the negative class, and computes a weighted average of these per-class statistics, with a per-class weight that is equal to the proportion of data in that class. A recent question on the Weka mailing list was whether the software also outputs micro-averaged precision, recall, and F-measure for multi-class problems. It turns out that it does! To find out where these can be found, read on.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://waikato.github.io/weka-blog/posts/2019-02-16-micro_average/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>github</category><guid>https://waikato.github.io/weka-blog/posts/2019-02-16-micro_average/</guid><pubDate>Sat, 16 Feb 2019 01:48:00 GMT</pubDate></item><item><title>Oversampling and Undersampling</title><link>https://waikato.github.io/weka-blog/posts/2019-01-30-sampling/</link><dc:creator>Eibe Frank</dc:creator><description>&lt;div&gt;&lt;p&gt;A frequent question of Weka users is how to implement oversampling or undersampling, which are two common strategies for dealing with imbalanced classes in classification problems. This post provides some explanation.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://waikato.github.io/weka-blog/posts/2019-01-30-sampling/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>github</category><guid>https://waikato.github.io/weka-blog/posts/2019-01-30-sampling/</guid><pubDate>Tue, 29 Jan 2019 23:10:00 GMT</pubDate></item><item><title>Making a Weka classifier</title><link>https://waikato.github.io/weka-blog/posts/2018-10-08-making-a-weka-classifier/</link><dc:creator>eibe</dc:creator><description>&lt;div&gt;&lt;p&gt;One role of the Weka software is to provide users with the opportunity to implement machine learning algorithms without having to deal with data import and evaluation issues: when a classifier has been written as a Java class that implements a couple of standard methods defined in the Weka framework, all the goodies that come with Weka are automatically applicable to it, and it will automatically show up in Weka's graphical user interfaces. To see what needs to be done, read on!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://waikato.github.io/weka-blog/posts/2018-10-08-making-a-weka-classifier/"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>github</category><guid>https://waikato.github.io/weka-blog/posts/2018-10-08-making-a-weka-classifier/</guid><pubDate>Mon, 08 Oct 2018 04:02:00 GMT</pubDate></item><item><title>Weka is now on Github</title><link>https://waikato.github.io/weka-blog/posts/2018-05-30-weka-on-github/</link><dc:creator>FracPete</dc:creator><description>&lt;div&gt;&lt;p&gt;In order to make Weka more accessible for people that like
having access to the latest code, we have been looking into
ways of bringing Weka to Github. Especially, since our
faculty already has an organizational account &lt;a class="reference external" href="https://github.com/Waikato"&gt;there&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, Weka was original stored in a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Concurrent_Versions_System"&gt;CVS&lt;/a&gt;
repository and then got migrated to &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Apache_Subversion"&gt;Subversion&lt;/a&gt;. Not only has it a lot of branches, not all of
them are publicly available, like commercial ones. This all
complicated the migration to Github.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://waikato.github.io/weka-blog/posts/2018-05-30-weka-on-github/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>github</category><guid>https://waikato.github.io/weka-blog/posts/2018-05-30-weka-on-github/</guid><pubDate>Wed, 30 May 2018 10:02:00 GMT</pubDate></item></channel></rss>